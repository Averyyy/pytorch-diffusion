{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Diffusion Probabilistic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data import DiffSet, ImageDataset\n",
    "import pytorch_lightning as pl\n",
    "from model import DiffusionModel\n",
    "from torch.utils.data import DataLoader\n",
    "import imageio\n",
    "import glob\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "diffusion_steps = 100\n",
    "dataset_choice = \"Fashion\"\n",
    "max_epoch = 5\n",
    "batch_size = 1\n",
    "\n",
    "# Loading parameters\n",
    "load_model = False\n",
    "load_version_num = 1\n",
    "\n",
    "dataroot = \"./datasets/real\"\n",
    "size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for optionally loading model\n",
    "pass_version = None\n",
    "last_checkpoint = None\n",
    "\n",
    "if load_model:\n",
    "    pass_version = load_version_num\n",
    "    last_checkpoint = glob.glob(\n",
    "        f\"./lightning_logs/{dataset_choice}/version_{load_version_num}/checkpoints/*.ckpt\"\n",
    "    )[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "# Create datasets and data loaders\n",
    "train_dataset = DiffSet(True, dataset_choice)\n",
    "val_dataset = DiffSet(False, dataset_choice)\n",
    "# transforms_ = [\n",
    "#                transforms.RandomCrop(size),\n",
    "#                transforms.RandomHorizontalFlip(),\n",
    "#                transforms.ToTensor(),\n",
    "#                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "# train_dataset = ImageDataset(dataroot, transforms_=transforms_)\n",
    "# val_dataset = ImageDataset(dataroot, transforms_=transforms_)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "# Create model and trainer\n",
    "if load_model:\n",
    "    model = DiffusionModel.load_from_checkpoint(last_checkpoint, in_size=train_dataset.size*train_dataset.size, t_range=diffusion_steps, img_depth=train_dataset.depth)\n",
    "else:\n",
    "    print(train_dataset.size)\n",
    "    model = DiffusionModel(train_dataset.size, diffusion_steps, train_dataset.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:446: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Load Trainer model\n",
    "tb_logger = pl.loggers.TensorBoardLogger(\n",
    "    \"lightning_logs/\",\n",
    "    name=dataset_choice,\n",
    "    version=pass_version,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epoch, \n",
    "    log_every_n_steps=10, \n",
    "    gpus=1, \n",
    "    auto_select_gpus=True,\n",
    "    resume_from_checkpoint=last_checkpoint, \n",
    "    logger=tb_logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name  | Type       | Params\n",
      "--------------------------------------\n",
      "0  | inc   | DoubleConv | 38.8 K\n",
      "1  | down1 | Down       | 295 K \n",
      "2  | down2 | Down       | 1.2 M \n",
      "3  | down3 | Down       | 2.4 M \n",
      "4  | up1   | Up         | 6.2 M \n",
      "5  | up2   | Up         | 1.5 M \n",
      "6  | up3   | Up         | 406 K \n",
      "7  | outc  | OutConv    | 195   \n",
      "8  | sa1   | SAWrapper  | 395 K \n",
      "9  | sa2   | SAWrapper  | 395 K \n",
      "10 | sa3   | SAWrapper  | 99.6 K\n",
      "--------------------------------------\n",
      "12.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.9 M    Total params\n",
      "51.681    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee8d4537f67468f9e2be21391ed5150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 torch.Size([1, 64, 256, 256])\n",
      "x2 torch.Size([1, 128, 128, 128]) torch.Size([1, 128, 128, 128])\n",
      "x3 torch.Size([1, 256, 64, 64]) torch.Size([1, 256, 64, 64])\n",
      "pre sa torch.Size([1, 256, 64, 64])\n",
      "post sa torch.Size([64, 256, 8, 8])\n",
      "x4: torch.Size([64, 256, 4, 4]) torch.Size([1, 512, 32, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (32) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mf:\\gdrive\\NYU Files\\Research\\Durf\\pytorch-diffusion\\entry.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/gdrive/NYU%20Files/Research/Durf/pytorch-diffusion/entry.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/gdrive/NYU%20Files/Research/Durf/pytorch-diffusion/entry.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, train_loader, val_loader)\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:582\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    581\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m--> 582\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    583\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    584\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:624\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    617\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[0;32m    619\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    620\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    621\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    622\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    623\u001b[0m )\n\u001b[1;32m--> 624\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[0;32m    626\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    627\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1061\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1057\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1059\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[1;32m-> 1061\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m   1063\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1064\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1140\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[0;32m   1139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1140\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1153\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_training_routine()\n\u001b[0;32m   1152\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[0;32m   1155\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1225\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1223\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m-> 1225\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1227\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1229\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    151\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[1;32m--> 152\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[0;32m    154\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:137\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[0;32m    136\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n\u001b[0;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:234\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[0;32m    225\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39m    the outputs of the step\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 234\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(hook_name, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[0;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1443\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1443\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1445\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\qiana\\anaconda3\\envs\\torchCuda\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[0;32m    389\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mvalidation_step(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\gdrive\\NYU Files\\Research\\Durf\\pytorch-diffusion\\model.py:124\u001b[0m, in \u001b[0;36mDiffusionModel.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidation_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m--> 124\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_loss(batch, batch_idx)\n\u001b[0;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39mval/loss\u001b[39m\u001b[39m\"\u001b[39m, loss)\n\u001b[0;32m    126\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mf:\\gdrive\\NYU Files\\Research\\Durf\\pytorch-diffusion\\model.py:96\u001b[0m, in \u001b[0;36mDiffusionModel.get_loss\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     91\u001b[0m     noise_imgs\u001b[39m.\u001b[39mappend(\n\u001b[0;32m     92\u001b[0m         (math\u001b[39m.\u001b[39msqrt(a_hat) \u001b[39m*\u001b[39m batch[i]) \u001b[39m+\u001b[39m\n\u001b[0;32m     93\u001b[0m         (math\u001b[39m.\u001b[39msqrt(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m a_hat) \u001b[39m*\u001b[39m epsilons[i])\n\u001b[0;32m     94\u001b[0m     )\n\u001b[0;32m     95\u001b[0m noise_imgs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(noise_imgs, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m e_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(noise_imgs, ts\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39;49mfloat))\n\u001b[0;32m     97\u001b[0m loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mmse_loss(\n\u001b[0;32m     98\u001b[0m     e_hat\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_size), epsilons\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_size)\n\u001b[0;32m     99\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mf:\\gdrive\\NYU Files\\Research\\Durf\\pytorch-diffusion\\model.py:61\u001b[0m, in \u001b[0;36mDiffusionModel.forward\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpost sa\u001b[39m\u001b[39m\"\u001b[39m, x3\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     59\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mx4:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown3(x3)\u001b[39m.\u001b[39mshape, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoding(\n\u001b[0;32m     60\u001b[0m     t, \u001b[39m512\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m8\u001b[39m)\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 61\u001b[0m x4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdown3(x3) \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_encoding(t, \u001b[39m256\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_size \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m8\u001b[39;49m)\n\u001b[0;32m     62\u001b[0m x4 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msa2(x4)\n\u001b[0;32m     63\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mup1(x4, x3) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoding(t, \u001b[39m128\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m4\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (32) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_shape = [3, 3]\n",
    "sample_batch_size = gif_shape[0] * gif_shape[1]\n",
    "n_hold_final = 10\n",
    "\n",
    "# Generate samples from denoising process\n",
    "gen_samples = []\n",
    "x = torch.randn((sample_batch_size, train_dataset.depth, train_dataset.size, train_dataset.size))\n",
    "sample_steps = torch.arange(model.t_range-1, 0, -1)\n",
    "for t in sample_steps:\n",
    "    x = model.denoise_sample(x, t)\n",
    "    if t % 50 == 0:\n",
    "        gen_samples.append(x)\n",
    "for _ in range(n_hold_final):\n",
    "    gen_samples.append(x)\n",
    "gen_samples = torch.stack(gen_samples, dim=0).moveaxis(2, 4).squeeze(-1)\n",
    "gen_samples = (gen_samples.clamp(-1, 1) + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process samples and save as gif\n",
    "gen_samples = (gen_samples * 255).type(torch.uint8)\n",
    "gen_samples = gen_samples.reshape(-1, gif_shape[0], gif_shape[1], train_dataset.size, train_dataset.size, train_dataset.depth)\n",
    "\n",
    "def stack_samples(gen_samples, stack_dim):\n",
    "    gen_samples = list(torch.split(gen_samples, 1, dim=1))\n",
    "    for i in range(len(gen_samples)):\n",
    "        gen_samples[i] = gen_samples[i].squeeze(1)\n",
    "    return torch.cat(gen_samples, dim=stack_dim)\n",
    "\n",
    "gen_samples = stack_samples(gen_samples, 2)\n",
    "gen_samples = stack_samples(gen_samples, 2)\n",
    "\n",
    "imageio.mimsave(\n",
    "    f\"{trainer.logger.log_dir}/pred.gif\",\n",
    "    list(gen_samples),\n",
    "    fps=5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
